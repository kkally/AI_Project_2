{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pjt_eye",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wv-VxK7DvjYk"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense, Activation, Conv2D, Flatten, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "plt.style.use('dark_background')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.load('/content/x_train.npy').astype(np.float32)\n",
        "y_train = np.load('/content/y_train.npy').astype(np.float32)\n",
        "x_val = np.load('/content/x_val.npy').astype(np.float32)\n",
        "y_val = np.load('/content/y_val.npy').astype(np.float32)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "OhEfY2HYwKjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc0b54-976d-4b9c-ab50-99eaa1121a4d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2586, 26, 34, 1) (2586, 1)\n",
            "(288, 26, 34, 1) (288, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2, 1, 1)"
      ],
      "metadata": {
        "id": "7YGc2XjewwBr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "8d574f6b-c18e-48ce-cae1-1174dc7f33cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f072f79dad0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2, 1, 1)\n",
        "plt.title(str(y_train[0]))\n",
        "plt.imshow(x_train[0].reshape((26, 34)), cmap='gray')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title(str(y_val[4]))\n",
        "plt.imshow(x_val[4].reshape((26, 34)), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "BjxidzpHrnPb",
        "outputId": "f11b61f7-e250-4db0-d6cd-370605e42527"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f069ac6a190>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(\n",
        "    x=x_train, y=y_train,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow(\n",
        "    x=x_val, y=y_val,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "38FJPOrjxK8t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(26, 34, 1))\n",
        "\n",
        "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
        "net = MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
        "net = MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
        "net = MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net = Flatten()(net)\n",
        "\n",
        "net = Dense(512)(net)\n",
        "net = Activation('relu')(net)\n",
        "net = Dense(1)(net)\n",
        "outputs = Activation('sigmoid')(net)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Jfz3oAyLWO",
        "outputId": "ca852ae0-55dd-4a44-9a96-6151027a9a1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               786944    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 880,129\n",
            "Trainable params: 880,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator, epochs=50, validation_data=val_generator,\n",
        "    callbacks=[\n",
        "        ModelCheckpoint('models/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JS8-bEuztam",
        "outputId": "17546a52-c88b-4814-c84c-4f06bcfea948"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4911 - acc: 0.7590\n",
            "Epoch 1: val_acc improved from -inf to 0.89583, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 14s 17ms/step - loss: 0.4834 - acc: 0.7649 - val_loss: 0.2576 - val_acc: 0.8958 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9056\n",
            "Epoch 2: val_acc improved from 0.89583 to 0.94097, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.2430 - acc: 0.9060 - val_loss: 0.1547 - val_acc: 0.9410 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9428\n",
            "Epoch 3: val_acc improved from 0.94097 to 0.94792, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.1710 - acc: 0.9435 - val_loss: 0.0827 - val_acc: 0.9479 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9457\n",
            "Epoch 4: val_acc improved from 0.94792 to 0.97222, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.1517 - acc: 0.9466 - val_loss: 0.0555 - val_acc: 0.9722 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9659\n",
            "Epoch 5: val_acc improved from 0.97222 to 0.97917, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0996 - acc: 0.9660 - val_loss: 0.0415 - val_acc: 0.9792 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9671\n",
            "Epoch 6: val_acc improved from 0.97917 to 0.98264, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0913 - acc: 0.9667 - val_loss: 0.0409 - val_acc: 0.9826 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0761 - acc: 0.9739\n",
            "Epoch 7: val_acc did not improve from 0.98264\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0763 - acc: 0.9741 - val_loss: 0.0332 - val_acc: 0.9826 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9730\n",
            "Epoch 8: val_acc improved from 0.98264 to 0.98611, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0838 - acc: 0.9733 - val_loss: 0.0327 - val_acc: 0.9861 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9765\n",
            "Epoch 9: val_acc improved from 0.98611 to 1.00000, saving model to models/2022_03_23_02_10_30.h5\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0771 - acc: 0.9764 - val_loss: 0.0179 - val_acc: 1.0000 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0684 - acc: 0.9783\n",
            "Epoch 10: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0678 - acc: 0.9783 - val_loss: 0.0174 - val_acc: 0.9965 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9826\n",
            "Epoch 11: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 12ms/step - loss: 0.0574 - acc: 0.9818 - val_loss: 0.0869 - val_acc: 0.9688 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9833\n",
            "Epoch 12: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0560 - acc: 0.9830 - val_loss: 0.0295 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9847\n",
            "Epoch 13: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0475 - acc: 0.9849 - val_loss: 0.0287 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0422 - acc: 0.9884\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0410 - acc: 0.9888 - val_loss: 0.0123 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0353 - acc: 0.9892\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0370 - acc: 0.9888 - val_loss: 0.0359 - val_acc: 0.9792 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0464 - acc: 0.9876\n",
            "Epoch 16: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0464 - acc: 0.9876 - val_loss: 0.0156 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0403 - acc: 0.9863\n",
            "Epoch 17: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0391 - acc: 0.9869 - val_loss: 0.0206 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0247 - acc: 0.9900\n",
            "Epoch 18: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0248 - acc: 0.9899 - val_loss: 0.0083 - val_acc: 0.9965 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0279 - acc: 0.9903\n",
            "Epoch 19: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0279 - acc: 0.9903 - val_loss: 0.0121 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0170 - acc: 0.9942\n",
            "Epoch 20: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0170 - acc: 0.9942 - val_loss: 0.0055 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 21/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9948\n",
            "Epoch 21: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0177 - acc: 0.9946 - val_loss: 0.0040 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 22/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9960\n",
            "Epoch 22: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0142 - acc: 0.9961 - val_loss: 0.0041 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.0127 - acc: 0.9959\n",
            "Epoch 23: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9953\n",
            "Epoch 24: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.0053 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0133 - acc: 0.9946\n",
            "Epoch 25: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0133 - acc: 0.9946 - val_loss: 0.0047 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0103 - acc: 0.9960\n",
            "Epoch 26: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0117 - acc: 0.9950 - val_loss: 0.0054 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9956\n",
            "Epoch 27: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 28/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9961\n",
            "Epoch 28: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0048 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0085 - acc: 0.9973\n",
            "Epoch 29: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0085 - acc: 0.9973 - val_loss: 7.4463e-04 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 30/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
            "Epoch 30: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0103 - acc: 0.9965 - val_loss: 8.5139e-04 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 31/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
            "Epoch 31: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 9.2581e-04 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 32/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9984\n",
            "Epoch 32: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 8.4153e-04 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 33/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
            "Epoch 33: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 34/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
            "Epoch 34: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 35/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
            "Epoch 35: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 16ms/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 36/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9969\n",
            "Epoch 36: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 17ms/step - loss: 0.0077 - acc: 0.9969 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 37/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
            "Epoch 37: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 38/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9964\n",
            "Epoch 38: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0092 - acc: 0.9965 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.9969\n",
            "Epoch 39: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 40/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0062 - acc: 0.9972\n",
            "Epoch 40: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9965\n",
            "Epoch 41: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0075 - acc: 0.9965 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9976\n",
            "Epoch 42: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9964\n",
            "Epoch 43: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9961\n",
            "Epoch 44: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
            "Epoch 45: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.0076 - acc: 0.9972\n",
            "Epoch 46: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0108 - acc: 0.9972\n",
            "Epoch 47: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9984\n",
            "Epoch 48: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 14ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.0058 - acc: 0.9992\n",
            "Epoch 49: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 13ms/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
            "Epoch 50: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f07202ff290>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "model = load_model('models/%s.h5' % (start_time))\n",
        "\n",
        "y_pred = model.predict(x_val/255.)\n",
        "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
        "\n",
        "print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
        "cm = confusion_matrix(y_val, y_pred_logical)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "XJxbNddx0Drs",
        "outputId": "e05c8022-d076-40b2-8c79-1ad334170d14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test acc: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f06b2279e50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.distplot(y_pred, kde=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "q3xcP2BP0T2e",
        "outputId": "081e5b2c-cf0b-47ad-da75-a3ba5a5af696"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, dlib\n",
        "import numpy as np\n",
        "from imutils import face_utils\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "IMG_SIZE = (34, 26)\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('/content/shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "model = load_model('/content/models/2022_03_23_02_10_30.h5')\n",
        "model.summary()\n",
        "\n",
        "def crop_eye(img, eye_points):\n",
        "  x1, y1 = np.amin(eye_points, axis=0)\n",
        "  x2, y2 = np.amax(eye_points, axis=0)\n",
        "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "  w = (x2 - x1) * 1.2\n",
        "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
        "\n",
        "  margin_x, margin_y = w / 2, h / 2\n",
        "\n",
        "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
        "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
        "\n",
        "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
        "\n",
        "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
        "\n",
        "  return eye_img, eye_rect\n",
        "\n",
        "# main\n",
        "cap = cv2.VideoCapture('/drive/eye_test.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, img_ori = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "\n",
        "  img = img_ori.copy()\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = detector(gray)\n",
        "\n",
        "  for face in faces:\n",
        "    shapes = predictor(gray, face)\n",
        "    shapes = face_utils.shape_to_np(shapes)\n",
        "\n",
        "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
        "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
        "\n",
        "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
        "\n",
        "    cv2_imshow(eye_img_l)\n",
        "    cv2_imshow(eye_img_r)\n",
        "\n",
        "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "\n",
        "    pred_l = model.predict(eye_input_l)\n",
        "    pred_r = model.predict(eye_input_r)\n",
        "\n",
        "    # visualize\n",
        "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
        "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
        "\n",
        "    state_l = state_l % pred_l\n",
        "    state_r = state_r % pred_r\n",
        "\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
        "\n",
        "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "\n",
        "  cv2_imshow(img)\n",
        "  if cv2.waitKey(1) == ord('q'):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h-keM3S2UZp",
        "outputId": "0bed598c-a340-483d-faa6-bdacad440f9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               786944    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 880,129\n",
            "Trainable params: 880,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}